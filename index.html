<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-7580334-2');
  </script>

  <title>Wenxuan Guo</title>

  <meta name="author" content="Wenxuan Guo">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6EJMX75K3R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-6EJMX75K3R');
</script>

<body>
  <!-- 将 max-width 从 800px 调为 860px，让内容区域更宽 -->
  <table style="width:100%;max-width:860px;border:0px;border-spacing:0px;border-collapse:separate;margin:0 auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- 顶部信息 -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Wenxuan Guo | 郭文轩</name>
                  </p>
                  <p>
                    I am a third-year Ph.D. student in the Department of Automation at Tsinghua University, advised by
                    <a href="https://ivg.au.tsinghua.edu.cn/~jfeng/index.html">Prof. Jianjiang Feng</a> and
                    <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Prof. Jiwen Lu</a>.
                    In 2022, I obtained my B.Eng. in the XUTELI School, Beijing Institute of Technology.
                    <br><br>
                    My research interests lie in <strong>computer vision</strong>. My current research focuses on
                    <strong>3D scene understanding</strong> and <strong>embodied intelligence</strong>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:gwx22@mails.tsinghua.edu.cn">Email</a> &nbsp;/&nbsp;
                    <a href="https://gwxuan.github.io/">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=yj--nvoAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/GWxuan">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:30%;max-width:30%">
                  <!-- 头像 -->
                  <a href="images/photo.jpg">
                    <img style="width:100%;max-width:100%" alt="profile photo" src="images/photo.jpg" class="hoverZoomLink">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- News -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <p>
                    <li style="margin: 5px;">
                      <b>2025-2:</b> TSP3D is accepted to CVPR2025 (Rating: 555)!!
                    </li>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Publications 标题 -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publications</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Publications 列表 -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:0 auto;">
            <tbody>

              <!-- 论文1：TSP3D -->
              <tr>
                <td style="padding:35px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="images/tsp3d-2.jpg" alt="TSP3D">
                </td>
                <td width="75%" valign="center">
                  <papertitle>TSP3D: Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding</papertitle>
                  <br>
                  <strong>Wenxuan Guo*</strong>,
                  <a href="https://xuxw98.github.io/">Xiuwei Xu</a>*,
                  <a href="https://ziweiwangthu.github.io/">Ziwei Wang</a>,
                  <a href="https://ivg.au.tsinghua.edu.cn/~jfeng/index.html">Jianjiang Feng</a>,
                  <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1">Jie Zhou</a>,
                  <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a>
                  <br>
                  <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025 (<em><strong style="color:red;">Rating: 555</strong></em>)
                  <br>
                  <a href="https://arxiv.org/abs/2502.10392">[arXiv]</a>
                  <a href="https://github.com/GWxuan/TSP3D">[Code]</a>
                  <a href="https://zhuanlan.zhihu.com/p/29557016028">[中文解读]</a>
                  <br>
                  <p>
                    We propose TSP3D, an efficient multi-level convolution architecture for
                    3D visual grounding. TSP3D achieves superior performance compared
                    to previous approaches in both accuracy and inference speed.
                  </p>
                </td>
              </tr>

              <!-- 论文2：Camera-LiDAR Cross-modality Gait Recognition -->
              <tr>
                <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <!-- 如果有配图，可替换为相应图片路径 -->
                  <img style="width:100%;max-width:100%" src="images/clgait.jpg" alt="CL-Gait">
                </td>
                <td width="75%" valign="center">
                  <papertitle>CL-Gait: Camera-LiDAR Cross-modality Gait Recognition</papertitle>
                  <br>
                  <strong>Wenxuan Guo*</strong>, Yingping Liang*, Zhiyu Pan, Ziheng Xi,
                  <a href="https://ivg.au.tsinghua.edu.cn/~jfeng/index.html">Jianjiang Feng</a>,
                  <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1">Jie Zhou</a>
                  <br>
                  <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2407.02038">[arXiv]</a>
                  <a href="https://github.com/GWxuan/CL-Gait">[Code]</a>
                  <br>
                  <p>
                    We propose CL-Gait, the first cross-modality gait recognition framework between camera
                    and LiDAR. We propose a contrastive pre-training method to align the feature spaces
                    of the two modalities, along with a large-scale data generation strategy.
                  </p>
                </td>
              </tr>

              <!-- 论文3：LiDAR-based person re-identification -->
              <tr>
                <td style="padding:40px 20px 20px 20px;width:30%;max-width:30%" align="center">
                  <!-- 如果有配图，可替换为相应图片路径 -->
                  <img style="width:100%;max-width:100%" src="images/reid3d.jpg" alt="LiDAR ReID">
                </td>
                <td style="padding-top:10px;" width="75%" valign="center">
                  <papertitle>ReID3D: LiDAR-based person re-identification</papertitle>
                  <br>
                  <span style="white-space: nowrap;">
                    <strong>Wenxuan Guo</strong>, Zhiyu Pan, Yingping Liang, Ziheng Xi, Zhicheng Zhong,
                    <a href="https://ivg.au.tsinghua.edu.cn/~jfeng/index.html">Jianjiang Feng</a>,
                    <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1">Jie Zhou</a>
                  </span>
                  <br>
                  <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2312.03033">[arXiv]</a>
                  <a href="https://github.com/GWxuan/ReID3D">[Code]</a>
                  <a href="https://zhuanlan.zhihu.com/p/685987170">[中文解读]</a>
                  <br>
                  <p>
                    We propose ReID3D, a LiDAR-based ReID framework that utilizes a pre-training strategy to
                    retrieve features of 3D body shape. Additionally, we build LReID — the first LiDAR-based
                    person ReID dataset, which is collected in several outdoor scenes with natural variations.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- 在 Publications 后新增 Selected Projects（仅IGL-Nav） -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:0 auto;margin-bottom:-20px;">
            <tbody>
              <tr>
                <td style="text-indent:20px;width:100%;vertical-align:middle">
                  <p><heading>Selected Projects</heading></p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <!-- 左侧：仅保留 IGL-Nav 视频 -->
                <td style="padding: 10px; width: 30%; max-width: 30%; text-align: center; vertical-align: middle;">
                  <video style="width:305px; height:200px;" controls>
                    <source src="images/igl-nav.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                  <p style="margin: 0; font-size: 12px; color: #555; margin-top: 5px;">IGL-Nav</p>
                </td>

                <!-- 右侧：IGL-Nav 文字介绍，去掉SG-Nav和UniGoal-->
                <td width="70%" style="vertical-align: middle; padding: 70px; text-align: left;">
                  <h3>3D Representation for Visual Navigation</h3>
                  <p>
                    We propose incremental 3D Gaussian localization for free-view image-goal navigation in 
                    <a href="https://GWxuan.github.io/IGL-Nav/">IGL-Nav</a>. We support a challenging application scenario 
                    where the camera for goal capturing and the agent's camera have very different intrinsics and poses, 
                    e.g., a cellphone and a RGB-D camera.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- 页脚模板 -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    <a href="https://jonbarron.info/">Website Template</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
    </tbody>
  </table>

  <!-- 底部小地球及版权声明 -->
  <p>
    <center>
      <div id="clustrmaps-widget" style="width:5%">
        <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=YNVFHRtkA_-Q9_ZWPs07MF8TluKHnbaO6fRySAhh7dI"></script>
      </div>
      <br>
      &copy; Wenxuan Guo | Last update: Mar. 13, 2025
    </center>
  </p>
</body>
</html>
